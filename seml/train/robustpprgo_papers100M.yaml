seml:
  name: rgnn_papers100M_train
  executable: experiment_train.py
  project_root_dir: ../..
  output_dir: seml/train/output

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 200G
    cpus-per-task: 12  # num cores
    time: 0-1:45     # max time, D-HH:MM

fixed:
  data_dir: /nfs/students/schmidtt/datasets/
  train_params:
    patience: 300
    max_epochs: 30
  artifact_dir: cache
  model_storage_type: pretrained
  device: 0


grid:
  dataset:
    type: choice
    options:
      - ogbn-papers100M
  binary_attr:
    type: choice
    options:
      #- True
      - False
  seed:
    type: choice
    options:
      - 0
      # - 1
      # - 5
  train_params:
    type: parameter_collection 
    params:
      lr:
        type: choice
        options: [5e-2, 1e-3, 5e-4]
      weight_decay:
        type: choice
        options: [1e-1, 1e-2, 5e-3]
  model_params:
    type: parameter_collection 
    params:
      hidden_size:              # Size of the MLP's hidden layer
        type: choice
        options: [64]
      nlayers:                   # Number of MLP layers
        type: choice
        options: [2]
      alpha:                      # PPR teleport probability
        type: choice
        options: [0.2, 0.25, 0.3, 0.4]
      mean_kwargs: 
        type: parameter_collection 
        params:
          temperature: 
            type: choice
            options: [1.0]
      dropout:                      
        type: choice
        options: [0.1]


# soft_median_pprgo:
#   fixed:
#     model_params:
#       label: Soft Median PPRGo
#       model: RobustPPRGo
#       ppr_normalization: 'row' 
#       do_cache_adj_prep: True
#       topk: 64
#       eps: 1e-2
#       mean: soft_median
#     train_params:
#       batch_size: 20480 # 16G
#       batch_mult_val: 1
#       forward_batch_size: 128
#     data_device: cpu
#     make_unweighted: True
#     make_undirected: False
#     normalize: False

pprgo:
  fixed:
    model_params:
      label: Vanilla PPRGo
      model: PPRGo
      ppr_normalization: 'row' 
      do_cache_adj_prep: True
      topk: 64
      eps: 1e-2
    train_params:
      batch_size: 20480 # 20G
      batch_mult_val: 1
      forward_batch_size: 128
    data_device: cpu
    make_unweighted: True
    make_undirected: False
    normalize: False
